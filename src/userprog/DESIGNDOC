		     +--------------------------+
		     |            OS            |
		     | PROJECT 2: USER PROGRAMS |
		     |     DESIGN DOCUMENT      |
		     +--------------------------+

---- GROUP ----

>> Fill in the names, email addresses and matriculation numbers of your group members.

Marco Maida <mmaida@mpi-sws.org> 416157
Marco Perronet <perronet@mpi-sws.org> 416159

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			   ARGUMENT PASSING
			   ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
  	...
    
    tid_t parent_tid;                   /* Parent thread identifier. */
    int exit_status;                    /* Exit status. */
    int child_born_status;              /* Child status after exec syscall. */                     
    bool waited;                        /* Process was waited by the father */
    struct file * run_file;             /* The file of the source code */
    
    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */

    /* List of threads that are waiting for this thread to exit. */
    struct list children_list;
    struct list_elem children_elem;

    /* Signal waiting parent when the process exits. */
    struct semaphore exit_sema;

    /* Signal the dying child process when its exit_status was read.
       This is needed to prevent it from deallocating before that happens. */
    struct semaphore exit_status_read_sema;

    /* Synchronize the father with the child during exec syscall. */
    struct semaphore child_sema;

    ...
  }

We added several new structs to thread in order to synchronize and do more 
bookkeping. Individual explanations in the comments.

struct args_struct
{
	char file_name[FILE_MAX];
	char file_args[ARG_MAX];
};

This struct is used to conveniently pass the command arguments 
to the load and setup_stack functions.
file_name is just the executable's name, without the arguments.
file_args is the executable's name plus its arguments.

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

The arguments are parsed in the order in which they are passed by the user 
(left to right) by using strtok_r().
It's fine to push them on the stack in this order, because they will always be
referenced by the pointers in argv[]. These pointers are simply saved in an array,
and then loaded in reversed order on the stack. This is important because the
calling convention imposes to push these pointers in reversed order.

To avoid overflow it's enough to check that the stack pointer is higher than
PHYS_BASE-PGSIZE before pushing on the stack. The stack pointer will never go above
PHYS_BASE because it's only decreased starting from PHYS_BASE.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

Because it's important for these functions to be reentrant. strtok() makes use of
a global variable to save the position of the last token in the string: this is
not safe when this function is called by multiple threads or in nested loops with
different calls to strtok().

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

1. The string manipulation is performed outside of the kernel, thus reducing
the work that the kernel has to do.
2. The fact that the string splitting is done in userspace reduces the risk
of kernel bugs.

			     SYSTEM CALLS
			     ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Represents an open file. */
struct file_descriptor 
{
  int fd_num;
  struct file *open_file;
  tid_t owner;

  struct list_elem elem; 
};

We use this struct to represent a file descriptor. File descriptors are 
stored in a global list.

struct lock files_lock;
unsigned int fd_count;

We added a lock to synchronize the file system and a counter to store the next
available fd number.

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

A list of file descriptors is stored in memory. Inside each file 
descriptor there is a pointer to an open file. File descriptors are unique 
within the entire OS. They are also unique within the entire execution 
as long as fd_count does not overflow.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

The major challenge here is to make sure that each memory address 
received belongs to the process that issued the syscall. In order to check
a single memory address, we need to make sure that
- The pointer ranges from 1 to PHYS_BASE
- The pointer belongs to a page instantiated for the process.
When checking a memory range, we need to repeat the test above multiple times,
ideally for each single address of the range. Doing so is correct, but would
result in useless overheads: due to the page system, we just need to check
- The first address (A)
- All the addresses that are k * PGSIZE distant from the first address. (B)
- The last address (C)

To visualize:
  page 1   page 2   page 3
|  _A__  |  _B__  |  C___ |


>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

When this happens, we check that the given memory range is valid. When
the memory to check is just one pointer, we just call page_dir_get_page()
once. Conversely, whenever we need to check a range, we perform the checks
described in (B3). In our algorithm, when exacly a page has to be checked,
we only check twice: the first and the last address, so the page table is
queried twice. 
If the initial address has offset 0, this number could be brought down to one: by considering the 
offset of the addresses we could deduce that the first and the last addresses 
fall in the same page. Exactly the same argument holds for two bytes, given a 
for example string of length 2.
Of course, we have to add to this number also the subsequent accesses to the
passed values.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

In the syscall infrastructure, we use the following macro to fetch a 
parameter:

#define GET_PARAM(esp,type)\
({\
    CHECK_PTR(esp);\
    type ret = *(type*)esp;\
    esp += sizeof(type*);\
    ret;\
})

CHECK_PTR() performs the error checking, and exits in case of errors.
This way, the code that fetches parameters with error-handling becomes 
much more readable:

In order not to forget resources, we explicitly handle error cases after
each call to a function. In order to make a clear distinction between
the syscall problems and file system access problems, we created a new file
called `fsaccess` and moved all the code about accessing the file system
(lock, file descriptors) there.

When we adopt all of these solutions, the resulting code in syscall.c becomes:

case SYS_READ:
  fd = GET_PARAM(esp, int);
  buffer = GET_PARAM(esp, void *);
  size = GET_PARAM(esp, unsigned);

  f->eax = read (fd, buffer, size); 
break;

...

static int read (int fd, void *buffer, unsigned length)
{
  CHECK_PTR_RANGE(buffer, buffer + length);
  return read_open_file(fd, buffer, length);
}


---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

Every process has in its thread struct:
* struct semaphore child_sema - A semaphore used to signal the father to stop waiting for our successful or unsuccsessful execution.
* int child_born_status - Used to tell the father process if the loading was
successful or unsuccsessful.

In the exec system call the process will wait on the semaphore after executing the
child process. The child process will then execute start_process(), in which
the executable image is loaded. After loading, the child will wake up the father
and return the success of the loading by doing:

parent_thread->child_born_status = (success ? 1 : -1); 
sema_up(&parent_thread->child_sema);

And the father will subsequently read the status.

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

# P calls wait(C) before C exits
This is the basic case, P will wait on the semaphore of the child, then when the
child exits it will unlock the semaphore, wait for the parent to read the exit
status (with another semaphore), then finally the parent will unlock the child, who
will exit.

# P calls wait(C) after C exits
In this case the father will look for C into its list of children and will
not wait because it won't be able to find it.

# How do you ensure that all resources are freed in each case?
All resources are freed on exit. The process' thread struct is then 
freed the next time the scheduler schedules it out.

# P terminates without waiting, before C exits
Every process unlocks all of his children's semaphores (exit_status_read_sema)
before exiting. This way, any child C can exit without being stuck on this
semaphore, which would never be unlocked by P, since it exited before.

# P terminates without waiting, after C exits
This doesn't present any problem, P will just terminate and not do anything
with any of the children. The children will remain hanging on the semaphore, then
when P exits it will release every child's semaphore, so all children will
subsequently exit.

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

It is lean and simple. It is just required to make some memory checks
in cascade (NULL check, PHYS_BASE check, valid page check).
To check for a range of addresses (i.e. when something potentially 
bigger than a page is passed to the kernel) it is sufficient to perform
the previous check multiple times (sup(range / PGSIZE) + 1 times).

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

A clear advantage is its simplicity. A file descriptor is just a struct,
referenced by a number and its owner. It is very easy to do bookkeping this way.
Every file descriptor is stored in a global list. A disadvantage of this approach
is that this requires O(n) access; a possible improvment could be to use an hash
table indexed by thread and add a list of file descriptors in each thread struct. 

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

It could be possible to map different kernel threads to a single user process.
This way, a process could have more threads, allowing for multithreading.
